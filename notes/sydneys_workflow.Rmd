---
title: "sydneys_workflow"
output: word_document
date: "2025-10-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "60%",fig.align='center')
```


## Load Libraries 
```{r}
# install.packages("here")   # only once allows us to all call from same space 
# install.packages("ResourceSelection")
# install.packages("randtests")
```
```{r}
library(tidyverse)
library(knitr)
library(tinytex) 
library(dplyr)
library(ggplot2)
library(readr)
library(tibble)
library(here)
library(ResourceSelection)
library(randtests)
library(purrr)
library(stringr)
library(mgcv)      # for GAM
library(glmmTMB)   # for mixed-effects logistic regression
```

## Load Datasets
```{r}
volley_points <- readr::read_csv(here("datasets", "volleyball_points_dataset.csv"))  
all_matches_CU <- readr::read_csv(here("datasets", "all_matches_CU.csv"))                #551 by 16
all_matches_opp <- readr::read_csv(here("datasets","all_matches_opp.csv"))               #551 by 16
all_matches_processed <- readr::read_csv(here("datasets","all_matches_processed.csv"))  #1102 by 16
all_matches <- readr::read_csv(here("datasets","all_matches (1).csv"))                 #269628 by 125 
```

```{r, eval = FALSE} 
#^^ makes code chunk not run
all_matches_raw <- readr::read_csv(here("datasets","all_matches_raw.csv"))              #269628 by 87
conference_matches_raw <- readr::read_csv(here("datasets","conference_matches_raw.csv"))   #168769 by 87
dirty_conference_matches_raw <- readr::read_csv(here("datasets","dirty_conference_matches_raw.csv"))   #259250 by 87
dirty_conference_matches <- readr::read_csv(here("datasets","dirty_conference_matches.csv"))          #259250 by 125
```

## Cleaning + Wrangling Data 
```{r, eval = FALSE}
#ALL MATCHES RAW
#selecting relevant/important variables
all_matches_raw1 <- all_matches_raw %>%
  select(match_id, point_id, time,team, player_number, player_name, player_id, skill, timeout, end_of_set, substitution, point, home_team_score, visiting_team_score, file_line_number, home_p1, home_p2, home_p3, home_p4, home_p5, home_p6, visiting_p1, visiting_p2, visiting_p3, visiting_p4, visiting_p5)  #269628 by 26 vars.

#checking NAs in data
na_count <- colSums(is.na(all_matches_raw1))
na_count_tbl <- enframe(na_count, name = "column", value = "num_NAs")
na_count_tbl
#shows us to take out set_code, set_type, start_zone, end_zone

all_matches_raw2 <- all_matches_raw1 %>%
  na.omit()    #269628 by 26 vars. -> 199758 observations 
```

```{r, eval = FALSE}
#CONFERENCE MATCHES RAW
conference_matches_raw1 <- conference_matches_raw %>%
  select(match_id, point_id, time,team, player_number, player_name, player_id, skill, timeout, end_of_set, substitution, point, home_team_score, visiting_team_score, file_line_number, home_p1, home_p2, home_p3, home_p4, home_p5, home_p6, visiting_p1, visiting_p2, visiting_p3, visiting_p4, visiting_p5)

#checking NAs in data
na_count <- colSums(is.na(conference_matches_raw1))
na_count_tbl <- enframe(na_count, name = "column", value = "num_NAs")
na_count_tbl

conference_matches_raw2 <- conference_matches_raw1 %>%
  na.omit()  # 168769 -> 125559 observations , 26 vars. 
```

```{r, eval = FALSE}
#DIRTY CONFERENCE MATCHES RAW 
dirty_conference_matches_raw1 <- dirty_conference_matches_raw %>%
  select(match_id, point_id, time,team, player_number, player_name, player_id, skill, timeout, end_of_set, substitution, point, home_team_score, visiting_team_score, file_line_number, home_p1, home_p2, home_p3, home_p4, home_p5, home_p6, visiting_p1, visiting_p2, visiting_p3, visiting_p4, visiting_p5)

#checking NAs in data
na_count <- colSums(is.na(dirty_conference_matches_raw1))
na_count_tbl <- enframe(na_count, name = "column", value = "num_NAs")
na_count_tbl
dirty_conference_matches_raw2 <- dirty_conference_matches_raw1 %>%
  na.omit()  # 259250 -> 192550 observations , 26 vars. 
```

##MAIN DATA CLEANING 
```{r}
#data inflow + outflow
#in_path  <- "all_matches"
in_path <- here::here("datasets", "all_matches (1).csv")
out_path <- "volleyball_points_dataset.csv"
```

```{r}
#touches <- read_csv(in_path, show_col_types = FALSE)
touches <- readr::read_csv(in_path, show_col_types = FALSE)

#normalize season column
touches <- touches %>%
  mutate(season = str_extract(season, "\\d{2}$"))

order_col <- if ("Unnamed: 0" %in% names(touches)) "Unnamed: 0" else NULL

#touches in correspondence to rally order   
touches_ord <- touches %>%
  {
    if (!is.null(order_col)) arrange(., match_id, set_number, .data[[order_col]])
    else group_by(., match_id, set_number) %>% arrange(row_number(), .by_group = TRUE) %>% ungroup()
  }
```

To compress rallies accurately, touches must be sorted in the exact sequence they occurred. We sort by match_id, set_number, and a stable row index so subsequent steps (like detecting score changes) behave correctly.

```{r}
#add flags for rally IDS + rally-ending scores 
touches_flagged <- touches_ord %>%
  filter(!is.na(home_team_score) | !is.na(visiting_team_score))  %>% # remove empty rows early 
  group_by(match_id, set_number) %>%
  mutate(
    prev_home  = lag(home_team_score),
    prev_away  = lag(visiting_team_score),
    rally_end_flag = (home_team_score != prev_home) | (visiting_team_score != prev_away),
    rally_end_flag = replace_na(rally_end_flag, TRUE),
    rally_id = cumsum(rally_end_flag),
    match_end_flag = last(to_logical_vec(won_match))  # NEW: indicates if this match was won by the "home" team 
    #TO LOOK AT WHOLE MATCH WIN PROB NOT JUST RALLY/SETS
  ) %>%
  ungroup()
```

Volleyball is rally scoring; each rally ends when the scoreboard moves. By turning score changes into a “flag” and cumulatively summing, every touch is assigned to the rally that produced (or followed) a point.

```{r}
#function to create binaries (T/F)
to_logical_vec <- function(x) {
  if (is.logical(x)) x
  else if (is.numeric(x)) x != 0
  else tolower(as.character(x)) %in% c("true","t","yes","y","1")
}
```

“Between points” events like timeouts are often recorded right after a point and before the next serve. We’ll roll them up with the rally that just ended (i.e., the point that triggered them).

```{r}
#SLIGHT CHANGE// added variables
#collapse touches into rally-level dataset
points_core <- touches_flagged %>%
  group_by(match_id, set_number, rally_id) %>%
  summarise(
    home_score_end           = last(home_team_score),
    away_score_end           = last(visiting_team_score),
    serving_team             = first(serving_team),          
    touches_in_rally         = n(),
    team_rotation            = suppressWarnings(as.integer(last(team_rotation))),
    opp_rotation             = suppressWarnings(as.integer(last(opp_rotation))),
    score_diff_raw           = suppressWarnings(as.integer(last(score_diff))),
    timeout_after_point      = any(to_logical_vec(timeout), na.rm = TRUE),
    substitution_after_point = any(to_logical_vec(substitution), na.rm = TRUE),
    #home_team_won_rally      = last(to_logical_vec(home_team_won)),  # new
    won_match_rally          = last(to_logical_vec(won_match)),      # new
    home_team                = last(home_team),
    visiting_team            = last(visiting_team),
    won_set                  = last(won_set),
    date                     = last(date),
    season                   = last(season),
    conference               = last(conference),
    .groups = "drop"
  ) %>%
  arrange(match_id, set_number, rally_id)
```

(JUST NOTED: Touches in rally is incorrect due to nature of all-matches data set with "empty" rows)
-We collapse many touches into a single rally row. We take last scores to capture the scoreboard after the point, and any() over timeout/sub to mark whether the inter-point stoppage happened following that point.

```{r}
#add point winner info. 
points_w_winner <- points_core %>%
  group_by(match_id, set_number) %>%
  mutate(
    prev_home_end = lag(home_score_end, default = 0),
    prev_away_end = lag(away_score_end, default = 0),
    home_delta    = home_score_end - prev_home_end,
    away_delta    = away_score_end - prev_away_end,
    point_winner_team = case_when(
      home_delta == 1 & away_delta == 0 ~ home_team,
      away_delta == 1 & home_delta == 0 ~ visiting_team,
      TRUE ~ NA_character_            
    )
  ) %>%
  ungroup()
```

Had some problems with timeout booleans. So above is the fix. Exactly one side’s score should increase by 1 at a rally end. Using deltas bypasses missing point_won_by values and avoids problems assigning winners when TO/Sub rows appear.

```{r}
#CU focused variables 
points_cu <- points_w_winner %>%
  mutate(
    cu_is_home        = home_team == "CU",
    cu_score_end      = if_else(cu_is_home, home_score_end, away_score_end),
    opp_score_end     = if_else(cu_is_home, away_score_end, home_score_end),
    cu_point_won      = point_winner_team == "CU",
    cu_score_diff_end = cu_score_end - opp_score_end,
    cu_serving        = serving_team == "CU"
  )
```

By aligning columns to CU, we can analyze run lengths, in-rally momentum, and timeout efficacy without worrying about home/away flipping your signs.
**ADD NEW
```{r}
#pre-rally state variables (for transitions)
points_cu <- points_cu %>%
  group_by(match_id, set_number) %>%
  arrange(rally_id) %>%
  mutate(
    cu_score_pre  = lag(cu_score_end, default = 0),
    opp_score_pre = lag(opp_score_end, default = 0),
    d_pre         = cu_score_pre - opp_score_pre
  ) %>%
  ungroup()
```

```{r}
#set/match + deciding vs nondeciding set 
points_cu <- points_cu %>%
  group_by(match_id) %>%
  mutate(
    total_sets = max(set_number, na.rm = TRUE),
    deciding_set = (set_number == total_sets),
    rally_in_match = row_number(),
    rally_prop_in_match = rally_in_match / n()
  ) %>%
  ungroup()
```

```{r}
#high leverage points 
points_cu <- points_cu %>%
  mutate(
    rally_importance = case_when(
      cu_score_end >= 20 | opp_score_end >= 20 ~ "late_set",
      TRUE ~ "early_mid_set"
    ),
    # Flag rallies where the score difference is small (≤ 2 points)
    #“close”//high-pressure moments
    close_score = abs(cu_score_diff_end) <= 2
  )
```

*may not use below but good to have.
```{r}
#momentum/clustering variables (detect run-length effects)
points_cu <- points_cu %>%
  group_by(match_id, set_number) %>%
  arrange(rally_id) %>%
  mutate(
    prev_win = lag(cu_point_won),
    # Assign a unique run ID whenever the rally result switches (win → loss)
    run_id = cumsum(cu_point_won != lag(cu_point_won, default = cu_point_won[1])),
    #Count how many rallies are in each consecutive run
    run_length = ave(seq_along(run_id), run_id, FUN = length)
  ) %>%
  ungroup()
```

```{r}
#final set-level scores 
set_scores <- touches_flagged %>%
  group_by(match_id, set_number) %>%
  summarise(
    final_home_set_score = max(home_team_score, na.rm = TRUE),
    final_away_set_score = max(visiting_team_score, na.rm = TRUE),
    .groups = "drop"
  )
```

```{r}
#DIFFERENT BY JUST ADDING FEW MORE VARIABLES 
points_final <- points_cu %>%
  left_join(set_scores, by = c("match_id", "set_number")) %>%
  select(
    match_id, date, season, conference,
    home_team, visiting_team, set_number, rally_id,
    cu_serving,
    cu_score_pre, opp_score_pre, d_pre,   # NEW
    cu_score_end, opp_score_end, cu_score_diff_end, cu_point_won,
    deciding_set, rally_importance, close_score, rally_in_match, rally_prop_in_match, run_length, prev_win, # NEW CONTEXT
    final_home_set_score, final_away_set_score,
    won_set,
    touches_in_rally, timeout_after_point, substitution_after_point,
    won_match_rally
  )
```

Final set scores provide outcome context for every rally (like late-set pressure).
```{r}
#output dataset
write_csv(points_final, out_path)

points <- points_final %>%
  na.omit()
```

```{r}
#export to github
readr::write_csv(points_final, "points_final.csv")
readr::write_csv(points_final, "points.csv")
```

#describe the data structure, dimensionality, variable types, and completeness. 
Points_final :  27,580 entries, 20 total columns
variables: match_id, date season, conference, home_team, visiting_team, set_number, rally_id, cu_serving, cu_score_end, opp_score_end, cu_score_diff_end, cu_point_won, final_home_set_score, final_away_set_score, won_set, touchs_in_rally, timeout_after_point, substitution_after_point, won_match_rally

NEW POINTS dataset: same 23916 entries, 20 variables (just NO NAs)

Volleyball_points_dataset:  27,580 entries, 16 total columns
variables: match_id, date season, conference, home_team, visiting_team, set_number, rally_id, cu_serving, cu_score_end, opp_score_end, cu_score_diff_end, cu_point_won, final_home_set_score, final_away_set_score, won_set

## Exploratory Analysis
```{r}
# quick overview of data 
glimpse(points_final)
summary(points_final)

#unique counts
points_final %>%
  summarize(
    matches = n_distinct(match_id),
    seasons = n_distinct(season),
    total_rallies = n(),
    unique_sets = n_distinct(paste(match_id, set_number))
  )
```
169 matches in 7 seasons with 27580 total rallies and 628 unique sets.

```{r}
# distribution of final set scores (CU perspective)
set_scores_cu <- points_final %>%
  group_by(match_id, set_number) %>%
  slice_tail(n = 1) %>%   # last rally of each set
  ungroup() %>%
  mutate(
    cu_final = cu_score_end,
    opp_final = opp_score_end,
    set_type = ifelse(set_number == 5, "deciding", "non-deciding")
  )

# histograms
ggplot(set_scores_cu, aes(x = cu_final)) + 
  geom_histogram(bins = 12) + 
  facet_wrap(~ set_type) + 
  labs(title = "Distribution of CU final set scores", x = "CU points at set end")

#table of common final scores
set_scores_cu %>%
  count(cu_final, opp_final) %>%
  arrange(desc(n)) %>%
  head(10) %>%
  knitr::kable()
```
Non-deciding sets have a greater number of sets with a) greater distribution of points at the sets end b) greater count of sets at a higher (more likely a win) # of points.

```{r}
#Basic summary stats
points_final %>%
  summarize(
    total_rallies = n(),
    cu_point_pct = mean(cu_point_won, na.rm = TRUE),
    cu_serv_pct = mean(cu_serving, na.rm = TRUE),
    sideout_rate = mean(if_else(cu_serving, !cu_point_won, cu_point_won), na.rm = TRUE), # side-out success
    substitution_rate = mean(substitution_after_point, na.rm = TRUE),
    won_match_rate = mean(won_match_rally, na.rm = TRUE)
  ) %>% kable()

# point-win by serving status
points_final %>%
  group_by(cu_serving) %>%
  summarize(
    p_win = mean(cu_point_won, na.rm = TRUE),
    n = n()
  ) %>% knitr::kable()
```

CU points wins ~50.36% of all points, regardless of serving.
CU served ~50.19% of the rallies, roughly an equal distribution.

Side-out success ~ 58.35%
CU wins ~ 58.35% of points when receiving the serve(side-out success).

CU wins ~42.04% of points when serving.
CU wins ~58.75% of points when receiving the serve.

```{r, eval = FALSE}
#touches_in_rally distribution
points_final %>%
  summarize(mean_touches = mean(touches_in_rally, na.rm = TRUE),
            median_touches = median(touches_in_rally, na.rm = TRUE),
            max_touches = max(touches_in_rally, na.rm = TRUE))

#timeouts distribution by set
points_final %>%
  group_by(set_number) %>%
  summarize(timeouts = sum(timeout_after_point, na.rm = TRUE),
            rallies = n(),
            to_per_rally = timeouts / rallies) %>%
  knitr::kable()
```

```{r}
#Distribution of substitutions per rally
ggplot(points_final, aes(x = substitution_after_point)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Distribution of Substitutions After Rallies",
       x = "Substitution Occurred?",
       y = "Number of Rallies")

#bar plot
ggplot(points_final, aes(x = factor(cu_serving), fill = cu_point_won)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "CU Point Win by Serving Status",
       x = "CU Serving?",
       y = "Percent of Rallies Won",
       fill = "CU Won Point")
```

```{r}
#Substitution effect on CU points
points_final %>%
  group_by(substitution_after_point) %>%
  summarize(
    avg_cu_point = mean(cu_point_won, na.rm = TRUE),
    n = n()
  ) %>% kable()

# Match outcome effect
points_final %>%
  group_by(won_match_rally) %>%
  summarize(
    avg_cu_point = mean(cu_point_won, na.rm = TRUE),
    n = n()
  ) %>% kable()
```


```{r}
#FINAL DATASET
points <- points_final %>%
  na.omit() #27580 obs -> 23916 obs. to get zero NAs, option
```

##OVERALL MARKOV MODELING PROCESS
## Sydneys attempt at markov chain modeling 
```{r}
#predictors
points2 <- points %>%
  mutate(
    y = as.integer(cu_point_won),                  # outcome: CU wins rally (0/1)
    cu_score_pre = cu_score_end - y,              # CU score before rally
    opp_score_pre = opp_score_end - (1L - y),     # Opponent score before rally
    d_pre = cu_score_pre - opp_score_pre,         # score differential pre-rally
    cu_serv = as.integer(cu_serving),             # 0/1 serving
    # Momentum: previous rallies won by CU
    prev_cu_win = lag(cu_point_won, default = 0),
    prev_cu_win2 = lag(cu_point_won, 2, default = 0)
  ) %>%
  filter(y %in% c(0,1), cu_serv %in% c(0,1))

#1 GAM: flexible spline + serving + momentum (bc data is not random)//mixed-effects logistic model
m_point_gam <- mgcv::gam(
  y ~ s(d_pre, k = 5) + cu_serv + prev_cu_win + prev_cu_win2 +
      substitution_after_point + won_match_rally,
  data = points2,
  family = binomial()
)
summary(m_point_gam)

#prediction grid
diff_grid <- expand.grid(
  d_pre = -7:7,
  cu_serv = c(0,1),
  prev_cu_win = c(TRUE, FALSE),
  prev_cu_win2 = c(TRUE, FALSE),
  substitution_after_point = c(TRUE, FALSE),
  won_match_rally = c(TRUE, FALSE)
)

#ensure types match model
diff_grid <- diff_grid %>%
  mutate(
    cu_serv = as.numeric(cu_serv),
    prev_cu_win = as.logical(prev_cu_win),
    prev_cu_win2 = as.logical(prev_cu_win2),
    substitution_after_point = as.logical(substitution_after_point),
    won_match_rally = as.logical(won_match_rally)
  )

#predict probabilities
pred_table <- diff_grid %>%
  mutate(
    eta = predict(m_point_gam$gam, newdata = diff_grid, type = "link"),
    p_hat = plogis(eta)
  ) %>%
  select(d_pre, cu_serv, prev_cu_win, prev_cu_win2,
         substitution_after_point, won_match_rally, p_hat)

print(pred_table)
```



#ETHANS Markov Chain Modeling for Probabilty of Winning a Rally
-do  Probability of Winning a set
-do Probability of Winning a match
```{r}
#change to points_final instead 
pbp <- readr::read_csv(here("datasets", "volleyball_points_dataset.csv"), show_col_types = FALSE)
```

```{r}
#derive pre-rally differential from end-of-rally scores
#Prepare predictors for a rally-level Markov chain
pbp2 <- pbp %>%
  mutate(
    y = as.integer(cu_point_won),        # outcome (1=CU won)
    cu_score_pre  = cu_score_end  - y,   # pre-rally CU score
    opp_score_pre = opp_score_end - (1L - y), # pre-rally opp score
    d_pre = cu_score_pre - opp_score_pre,
    cu_serv = as.integer(cu_serving)     # CU serving (0/1)
  ) %>%
  filter(y %in% c(0,1), cu_serv %in% c(0,1))

#fit simplified logistic model
m_point <- glm(
  y ~ poly(d_pre, 2, raw = TRUE) + cu_serv, #only uses score_diff + serve
  data = pbp2, family = binomial()
)

summary(m_point)

#build table of predicted probabilities
diff_grid <- expand.grid(
  d_pre = -7:7,
  cu_serv = c(0,1)
)

pred_table <- diff_grid %>%
  mutate(
    eta = predict(m_point, newdata = diff_grid, type = "link"),
    p_hat = plogis(eta),
    cu_serving = ifelse(cu_serv == 1, "Yes", "No")
  ) %>%
  select(d_pre, cu_serving, p_hat)

print(pred_table)
```


```{r}
m_null <- glm(y ~ 1, data = pbp2, family = binomial())
anova(m_null, m_point, test = "Chisq")
```

```{r}
install.packages("pROC")

library(pROC)
pbp2$p_hat <- predict(m_point, type = "response")
roc_obj <- roc(pbp2$y, pbp2$p_hat)
auc(roc_obj)
plot(roc_obj, main = paste("AUC =", round(auc(roc_obj), 3)))
```

```{r}
predict(m_point, newdata = data.frame(d_pre = 0, cu_serv = 1), type = "response")  # tied score, CU serving
predict(m_point, newdata = data.frame(d_pre = 0, cu_serv = 0), type = "response")  # tied score, opp serving
predict(m_point, newdata = data.frame(d_pre = 5, cu_serv = 1), type = "response")  # CU up 5, serving
predict(m_point, newdata = data.frame(d_pre = -5, cu_serv = 0), type = "response") # CU down 5, opp serving
```

```{r}
library(boot)
cv_error <- cv.glm(pbp2, m_point, K = 10)$delta
cv_error
```


1.  **Define the state space.**\
    A state is the pre-rally score and server: $$
    (a,b,s),\quad a=\text{CU points},\; b=\text{opponent points},\; s\in\{\text{CU},\text{Opp}\}.
    $$ Absorbing if $a\ge T$ and $a-b\ge2$ (CU wins) or $b\ge T$ and $b-a\ge2$ (opp wins), with $T=25$ (or $15$ in the deciding set).

2.  **Estimate point-win probabilities.**\
    Fit a logistic model for $$
    p(d,s)=\Pr(\text{CU wins next rally}\mid d,s),
    $$ where $d=a-b$ (score differential) and $s$ is whether CU is serving.

3.  **Map to transitions.**\
    From any non-absorbing $(a,b,s)$:

    -   with probability $p(d,s)$ go to $(a+1,b,\text{CU})$\
    -   with probability $1-p(d,s)$ go to $(a,b+1,\text{Opp})$\
        (Rally winner serves next.)

4.  **Solve the absorbing Markov chain.**\
    Let $W(a,b,s)$ be the probability CU wins the set from $(a,b,s)$. Then $$
    W(a,b,s)=p(d,s)\,W(a+1,b,\mathrm{CU})+\big(1-p(d,s)\big)\,W(a,b+1,\mathrm{Opp}),
    $$ with $W=1$ in CU-win absorbing states and $W=0$ in CU-loss absorbing states. Compute via memoized recursion (DP).

5.  **Attach live win probabilities.**\
    For each rally, compute pre-rally $(a,b)$, serving $s$, and $T$; evaluate $W(a,b,s)$ to get pre-rally set win probability.

6.  **Validate & calibrate.**\
    Use Brier score and reliability plots; check that WP rises after CU-won rallies and falls after losses.

7.  **(Maybe) Extend to match-win probability.**\
    Embed set-level $W$ in a best-of-five framework, tracking sets won until a team reaches three.


#PLOTS WITH MARKOV MODELING 
```{r}
#score-state heatmap + frequency of states 
score_states <- pbp2 %>%
  mutate(
    cu_pre = cu_score_pre,
    opp_pre = opp_score_pre
  ) %>%
  count(cu_pre, opp_pre) %>%
  ungroup()

ggplot(score_states, aes(x = opp_pre, y = cu_pre, fill = n)) +
  geom_tile() +
  scale_fill_viridis_c() +
  labs(title = "Frequency of pre-rally score states (CU vs Opp)", x = "Opponent points (pre-rally)", y = "CU points (pre-rally)")
```
Shows where most rallies occur, not that useful.

```{r}
#empirical transition matrix 
empirical_p <- pbp2 %>%
  group_by(d_pre, cu_serv) %>%
  summarize(
    n = n(),
    p_emp = mean(y, na.rm = TRUE)
  ) %>%
  ungroup()

ggplot(empirical_p, aes(x = d_pre, y = p_emp, color = factor(cu_serv))) +
  geom_point() + geom_smooth(method = "loess", se = FALSE) +
  labs(title = "Empirical p(next rally | diff, serve)", x = "Score diff (CU - Opp) pre-rally", color = "CU serving")
```


## Assumptions
#Met/ or not by our model
Independence & Markov assumption checks
-We cannot fully "prove" Markov, but we can test if the previous few rallies (beyond pre-rally scores) have additional predictive power.
```{r}
#add lagged outcomes and test
# within match-set grouping, compute last 3 outcomes
pbp_lags <- pbp2 %>%
  group_by(match_id, set_number) %>%
  arrange(rally_id) %>%
  mutate(
    lag1 = lag(y, 1),
    lag2 = lag(y, 2),
    lag3 = lag(y, 3)
  ) %>%
  ungroup()

# model with lags
m_with_lags <- glm(y ~ poly(d_pre, 2, raw = TRUE) + cu_serv + lag1 + lag2 + lag3,
                   data = pbp_lags, family = binomial())

summary(m_point)       # original
summary(m_with_lags)   # with lags; check significance of lag terms
```

The inclusion of lagged rally outcomes (previous 1–3 rallies) did not improve predictive power once score difference and serve status were accounted for. This suggests that rally outcomes are conditionally independent given the current score state, supporting the Markov(1) assumption in our win probability modeling. Good.


```{r}
# unique matches
match_ids <- unique(pbp2$match_id)

# run runs.test for each match
runs_list <- map(match_ids, function(mid) {
  dat <- pbp2 %>% filter(match_id == mid) %>% pull(y)
  n_wins <- sum(dat == 1, na.rm = TRUE)
  n_losses <- sum(dat == 0, na.rm = TRUE)
  
  if (n_wins > 0 & n_losses > 0) {
    out <- tryCatch(runs.test(as.numeric(dat)), error = function(e) NULL)
    if (!is.null(out)) {
      return(tibble(
        match_id = mid,
        n_wins = n_wins,
        n_losses = n_losses,
        runs = out$runs,
        statistic = out$statistic,
        p_value = out$p.value
      ))
    }
  }
  # fallback row w/ NAs
  tibble(
    match_id = mid,
    n_wins = n_wins,
    n_losses = n_losses,
    runs = NA_real_,
    statistic = NA_real_,
    p_value = NA_real_
  )
})

#combine results
runs_clean <- bind_rows(runs_list)
summary(runs_clean$p_value)
hist(runs_clean$p_value, main = "Runs Test p-values across matches")
```

Min.   = 0.00735   (smallest p-value)
1st Qu.= 0.01300   (25% of p-values are ≤ 0.013)
Median = 0.01864   (half are ≤ 0.01864)
Mean   = 0.03543   (average p-value)
3rd Qu.= 0.04947   (75% of p-values are ≤ 0.049)
Max.   = 0.08030   (largest p-value)
NA's   = 166       (runs test couldn’t be computed for 166 cases)

Almost all p-values are very small (most < 0.05). That means the runs test is consistently rejecting the null hypothesis of randomness in rally outcomes. Good. 

## Model calibration 
```{r}
# predicted probs from logistic 
pbp2$pred <- predict(m_point, type = "response")

# Brier score
brier <- mean((pbp2$y - pbp2$pred)^2)
brier

# calibration bins
calib <- pbp2 %>%
  mutate(bin = ntile(pred, 10)) %>%
  group_by(bin) %>%
  summarize(
    mean_pred = mean(pred),
    mean_obs = mean(y),
    n = n()
  )

ggplot(calib, aes(x = mean_pred, y = mean_obs)) +
  geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Calibration plot (deciles of predicted probability)", x = "Mean predicted prob", y = "Observed proportion")

# Hosmer-Lemeshow
hl <- hoslem.test(pbp2$y, pbp2$pred, g = 10)
hl
```
The Brier score measures average squared error between predicted probabilities and actual outcomes. It ranges from 0 (perfect) to 0.25 for a balanced 50/50 prediction problem (random guessing gives ~0.25). Model’s score (~0.243) is only slightly better than random guessing. 

Hosmer–Lemeshow GOF test: 
Null hypothesis (H₀): The model fits well (predicted probs = observed probs in groups).
p = 0.35 > 0.05 → Fail to reject H₀.
No evidence of lack of fit as the model’s predicted probabilities are statistically consistent with the observed data. Good.

The model is well calibrated (its probabilities match outcomes on average) but has limited predictive strength (it struggles to confidently separate winning and losing rallies).
This is expected, given that only score differential and serving status were used. Factors like rotations, player quality, or set context are not included.



```{r}
#cross validation + temporal holdout 
train <- pbp2 %>% filter(season <= 19)
test  <- pbp2 %>% filter(season >= 20)

m_train <- glm(y ~ poly(d_pre, 2, raw = TRUE) + cu_serv, data = train, family = binomial())
test$pred <- predict(m_train, newdata = test, type = "response")
brier_test <- mean((test$y - test$pred)^2)
brier_test
```
Model’s test Brier = 0.52, which is very poor. Worse than random > 0.25.

THIS IS BECAUSE OF THE SEASON FILTER. THE REAL VALUES DO NOT INCLUDE 20 (18-24) AND IF CU WINS POINT, INCLUDE CU (CU 18-CU 24).

```{r}
library(dplyr)
library(pROC)
library(ggplot2)

set.seed(42)

match_ids <- unique(pbp2$match_id)
train_ids <- sample(match_ids, size = floor(0.8 * length(match_ids)))
train <- pbp2 %>% filter(match_id %in% train_ids)
test  <- pbp2 %>% filter(!match_id %in% train_ids)

m_train <- glm(y ~ poly(d_pre, 2, raw = TRUE) + cu_serv,
               data = train, family = binomial())

test <- test %>%
  mutate(pred = predict(m_train, newdata = ., type = "response"))

brier_test <- mean((test$y - test$pred)^2, na.rm = TRUE)
brier_test

auc_val <- auc(test$y, test$pred, na.rm = TRUE)
auc_val

calib <- test %>%
  mutate(bin = ntile(pred, 10)) %>%
  group_by(bin) %>%
  summarise(mean_pred = mean(pred), mean_obs = mean(y), n = n(), .groups = "drop")

ggplot(calib, aes(mean_pred, mean_obs, size = n)) +
  geom_point(alpha = 0.8) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Calibration (deciles, test set)",
       x = "Mean predicted probability",
       y = "Observed proportion") +
  theme_minimal()

```
After randomly splitting rallies into training (80%) and testing (20%) sets, the model achieved an out-of-sample Brier score of 0.24, indicating modest but consistent predictive accuracy.
This value is only slightly better than the 0.25 baseline expected for random guessing, which aligns with the limited information available in rally-level predictors (score differential and serving status).
The model remains well-calibrated and provides a realistic foundation for constructing transition probabilities in our Markov chain win-probability framework.


##ANOTHER ATTEMPT
##MARKOV MODELING PROCESS (SYDNEY)
```{r}
data_for_mc <- points
```

```{r}
#define rally importance + closeness
data_for_mc <- data_for_mc %>%
  mutate(
    rally_importance = case_when(
      cu_score_end >= 20 | opp_score_end >= 20 ~ "late_set",
      TRUE ~ "early_mid_set"
    ),
    close_score = abs(cu_score_diff_end) <= 2
  )

#compute pre-rally score difference 
data_for_mc <- data_for_mc %>%
  group_by(match_id, set_number) %>%
  arrange(rally_id) %>%
  mutate(
    d_pre = lag(cu_score_diff_end, default = 0)  # score difference before rally
  ) %>%
  ungroup()
```

1. Define Markov States for the Markov Chain
```{r}
data_for_mc <- data_for_mc %>%
  mutate(
    # Discretize score difference into bins for Markov states
    d_bin = case_when(
      d_pre <= -5 ~ "-5 or less",
      d_pre >= 5  ~ "5 or more",
      TRUE        ~ as.character(d_pre)
    ),
    #combine with rally stage (early vs late)
    state = paste(d_bin, rally_importance, sep = "_")
  )
```

2. Build Transition Table
```{r}
transitions <- data_for_mc %>%
  group_by(match_id, set_number) %>%
  arrange(rally_id) %>%
  mutate(next_state = lead(state)) %>%
  filter(!is.na(next_state)) %>%
  ungroup()

# Count transitions for probability estimation
transition_matrix <- transitions %>%
  count(state, next_state) %>%
  group_by(state) %>%
  mutate(prob = n / sum(n)) %>%
  ungroup()

head(transition_matrix)
```

3. Absorbing States for set/match Outcomes
```{r}
data_for_mc <- data_for_mc %>%
  mutate(
    absorbing_set_state = if_else(won_set, "SetWon", "SetLost"),
    absorbing_match_state = if_else(won_match_rally, "MatchWon", "MatchLost")
  )
```

7. Markov Chain Model Implementation
```{r}
simulate_match <- function(transitions, start_state, n_rallies = 50) {
  states <- start_state
  for(i in 1:n_rallies) {
    current_state <- tail(states, 1)
    next_probs <- transitions %>% filter(state == current_state)
    if(nrow(next_probs) == 0) break
    next_state <- sample(next_probs$next_state, 1, prob = next_probs$prob)
    states <- c(states, next_state)
    if(next_state %in% c("SetWon", "SetLost")) break
  }
  return(states)
}
```







#Cluster Analysis 



