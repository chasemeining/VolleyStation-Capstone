---
title: "STAT_capstone"
output: word_document
date: "2025-09-11"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "60%",fig.align='center')
```


1. Ethan + Sydney's data cleaning and transformation combined here.
## Load Libraries 
```{r}
library(tidyverse)
library(knitr)
library(tinytex) 
library(dplyr)
library(ggplot2)
library(readr)
library(tibble)
library(here)
library(ResourceSelection)
library(randtests)
library(purrr)
library(stringr)
library(mgcv)      # for GAM
library(car)       #applied regression NEW
library(visreg)   #visulization of regression models NEW
```

## Load Datasets
```{r}
volley_points <- readr::read_csv(here("datasets", "volleyball_points_dataset.csv"))  
all_matches_CU <- readr::read_csv(here("datasets", "all_matches_CU.csv"))                #551 by 16
all_matches_opp <- readr::read_csv(here("datasets","all_matches_opp.csv"))               #551 by 16
all_matches_processed <- readr::read_csv(here("datasets","all_matches_processed.csv"))  #1102 by 16
all_matches <- readr::read_csv(here("datasets","all_matches (1).csv"))                 #269628 by 125 
```

##DATA CLEANING 
```{r}
#data inflow + outflow
in_path <- here::here("datasets", "all_matches (1).csv")
out_path <- "volleyball_points_dataset.csv"
```

```{r}
touches <- readr::read_csv(in_path, show_col_types = FALSE)

#normalize season column
touches <- touches %>%
  mutate(season = str_extract(season, "\\d{2}$"))

order_col <- if ("Unnamed: 0" %in% names(touches)) "Unnamed: 0" else NULL

#touches in correspondence to rally order   
touches_ord <- touches %>%
  {
    if (!is.null(order_col)) arrange(., match_id, set_number, .data[[order_col]])
    else group_by(., match_id, set_number) %>% arrange(row_number(), .by_group = TRUE) %>% ungroup()
  }
```
To compress rallies accurately, touches must be sorted in the exact sequence they occurred. We sort by match_id, set_number, and a stable row index so subsequent steps (like detecting score changes) behave correctly.

```{r}
#add flags for rally IDS + rally-ending scores 
touches_flagged <- touches_ord %>%
  filter(!is.na(home_team_score) | !is.na(visiting_team_score))  %>% # remove empty rows early 
  group_by(match_id, set_number) %>%
  mutate(
    prev_home  = lag(home_team_score),
    prev_away  = lag(visiting_team_score),
    rally_end_flag = (home_team_score != prev_home) | (visiting_team_score != prev_away),
    rally_end_flag = replace_na(rally_end_flag, TRUE),
    rally_id = cumsum(rally_end_flag),
    match_end_flag = as.logical(last(won_match)) 
    #match_end_flag = last(to_logical_vec(won_match))  # NEW: indicates if this match was won by the "home" team 
    #TO LOOK AT WHOLE MATCH WIN PROB NOT JUST RALLY/SETS
  ) %>%
  ungroup()
```
Volleyball is rally scoring; each rally ends when the scoreboard moves. By turning score changes into a “flag” and cumulatively summing, every touch is assigned to the rally that produced (or followed) a point.

```{r}
#function to create binaries (T/F)
to_logical_vec <- function(x) {
  if (is.logical(x)) x
  else if (is.numeric(x)) x != 0
  else tolower(as.character(x)) %in% c("true","t","yes","y","1")
}
```
“Between points” events like timeouts are often recorded right after a point and before the next serve. We’ll roll them up with the rally that just ended (i.e., the point that triggered them).

```{r}
#collapse touches into rally-level dataset
points_core <- touches_flagged %>%
  group_by(match_id, set_number, rally_id) %>%
  summarise(
    home_score_end           = last(home_team_score),
    away_score_end           = last(visiting_team_score),
    serving_team             = first(serving_team),          
    touches_in_rally         = n(),
    team_rotation            = suppressWarnings(as.integer(last(team_rotation))),
    opp_rotation             = suppressWarnings(as.integer(last(opp_rotation))),
    score_diff_raw           = suppressWarnings(as.integer(last(score_diff))),
    timeout_after_point      = any(to_logical_vec(timeout), na.rm = TRUE),
    substitution_after_point = any(to_logical_vec(substitution), na.rm = TRUE),
    #home_team_won_rally      = last(to_logical_vec(home_team_won)),  # new
    won_match_rally          = last(to_logical_vec(won_match)),      # new
    home_team                = last(home_team),
    visiting_team            = last(visiting_team),
    won_set                  = last(won_set),
    date                     = last(date),
    season                   = last(season),
    conference               = last(conference),
    .groups = "drop"
  ) %>%
  arrange(match_id, set_number, rally_id)
```
(JUST NOTED: Touches in rally is incorrect due to nature of all-matches data set with "empty" rows)
-We collapse many touches into a single rally row. We take last scores to capture the scoreboard after the point, and any() over timeout/sub to mark whether the inter-point stoppage happened following that point.

```{r}
#add point winner info. 
points_w_winner <- points_core %>%
  group_by(match_id, set_number) %>%
  mutate(
    prev_home_end = lag(home_score_end, default = 0),
    prev_away_end = lag(away_score_end, default = 0),
    home_delta    = home_score_end - prev_home_end,
    away_delta    = away_score_end - prev_away_end,
    point_winner_team = case_when(
      home_delta == 1 & away_delta == 0 ~ home_team,
      away_delta == 1 & home_delta == 0 ~ visiting_team,
      TRUE ~ NA_character_            
    )
  ) %>%
  ungroup()
```
Had some problems with timeout booleans. So above is the fix. Exactly one side’s score should increase by 1 at a rally end. Using deltas bypasses missing point_won_by values and avoids problems assigning winners when TO/Sub rows appear.

```{r}
#CU focused variables 
points_cu <- points_w_winner %>%
  mutate(
    cu_is_home        = home_team == "CU",
    cu_score_end      = if_else(cu_is_home, home_score_end, away_score_end),
    opp_score_end     = if_else(cu_is_home, away_score_end, home_score_end),
    cu_point_won      = point_winner_team == "CU",
    cu_score_diff_end = cu_score_end - opp_score_end,
    cu_serving        = serving_team == "CU"
  )
```
By aligning columns to CU, we can analyze run lengths, in-rally momentum, and timeout efficacy without worrying about home/away flipping your signs.

```{r}
#pre-rally state variables (for transitions)
points_cu <- points_cu %>%
  group_by(match_id, set_number) %>%
  arrange(rally_id) %>%
  mutate(
    cu_score_pre  = lag(cu_score_end, default = 0),
    opp_score_pre = lag(opp_score_end, default = 0),
    d_pre         = cu_score_pre - opp_score_pre
  ) %>%
  ungroup()
```

```{r}
#set/match + deciding vs non deciding set 
points_cu <- points_cu %>%
  group_by(match_id) %>%
  mutate(
    total_sets = max(set_number, na.rm = TRUE),
    deciding_set = (set_number == total_sets),
    rally_in_match = row_number(),
    rally_prop_in_match = rally_in_match / n()
  ) %>%
  ungroup()
```

```{r}
#high leverage points 
points_cu <- points_cu %>%
  mutate(
    rally_importance = case_when(
      cu_score_end >= 20 | opp_score_end >= 20 ~ "late_set",
      TRUE ~ "early_mid_set"
    ),
    # Flag rallies where the score difference is small (≤ 2 points)
    #“close”//high-pressure moments
    close_score = abs(cu_score_diff_end) <= 2
  )
```

```{r}
#momentum/clustering variables (detect run-length effects)
points_cu <- points_cu %>%
  group_by(match_id, set_number) %>%
  arrange(rally_id) %>%
  mutate(
    prev_win = lag(cu_point_won),
    # Assign a unique run ID whenever the rally result switches (win → loss)
    run_id = cumsum(cu_point_won != lag(cu_point_won, default = cu_point_won[1])),
    #Count how many rallies are in each consecutive run
    run_length = ave(seq_along(run_id), run_id, FUN = length)
  ) %>%
  ungroup()
```

```{r}
#final set-level scores 
set_scores <- touches_flagged %>%
  group_by(match_id, set_number) %>%
  summarise(
    final_home_set_score = max(home_team_score, na.rm = TRUE),
    final_away_set_score = max(visiting_team_score, na.rm = TRUE),
    .groups = "drop"
  )
```

```{r}
points_final <- points_cu %>%
  left_join(set_scores, by = c("match_id", "set_number")) %>%
  select(
    match_id, date, season, conference,
    home_team, visiting_team, set_number, rally_id,
    cu_serving,
    cu_score_pre, opp_score_pre, d_pre,   # NEW
    cu_score_end, opp_score_end, cu_score_diff_end, cu_point_won,
    deciding_set, rally_importance, close_score, rally_in_match, rally_prop_in_match, run_length, prev_win, 
    final_home_set_score, final_away_set_score,
    won_set,
    touches_in_rally, timeout_after_point, substitution_after_point,
    won_match_rally
  )
```

Final set scores provide outcome context for every rally (like late-set pressure).
```{r}
#output dataset
write_csv(points_final, out_path)

points <- points_final %>%
  na.omit()
```

```{r}
#export to github
readr::write_csv(points_final, "points_final.csv")
#readr::write_csv(points_final, "points.csv")
```

Points_final: 27580, 30 variables 
variables: match_id, date, season, conference, home_team, visiting_team, set_number, rally_id, cu_serving, cu_score_pre, opp_score_pre, d_pre, cu_score_end, opp_score_end, cu_score_diff_end, cu_point_won, deciding_set, rally_importance, close_score, rally_in_match, rally_prop_in_match, run_length, prev_win, final_home_set_score, final_away_set_score, won_set, touches_in_rally, timeout_after_point, substitution_after_point, won_match_rally

Points: 23365 entries , 30 variables (NO NAs)

*Different Dataset Uses*
Use the clean (no NAs) dataset (points) for model fitting, validation, and markov property testing (assumptions).
Use the full dataset (points_final) for descriptive summaries, exploratory visuals, and robustness checks.


## Exploratory Analysis + General Summary Statstics 
```{r}
#quick overview of data 
summary(points)

#unique counts for both datasets 
points_final %>%
  summarize(
    matches = n_distinct(match_id),
    seasons = n_distinct(season),
    total_rallies = n(),
    unique_sets = n_distinct(paste(match_id, set_number))
  )

points %>%
  summarize(
    matches = n_distinct(match_id),
    seasons = n_distinct(season),
    total_rallies = n(),
    unique_sets = n_distinct(paste(match_id, set_number))
  )
```
For points_final: 169 matches in 7 seasons with 27580 total rallies and 628 unique sets. 27580, 30 variables 
For points: 148 matches, 6 seasons, 23365 total rallies, 548 unique sets.23365 entries , 30 variables (NO NAs)

```{r}
#Basic summary stats
points_final %>%
  summarize(
    total_rallies = n(),
    cu_point_pct = mean(cu_point_won, na.rm = TRUE),
    cu_serv_pct = mean(cu_serving, na.rm = TRUE),
    sideout_rate = mean(if_else(cu_serving, !cu_point_won, cu_point_won), na.rm = TRUE), # side-out success
    substitution_rate = mean(substitution_after_point, na.rm = TRUE),
    won_match_rate = mean(won_match_rally, na.rm = TRUE)
  ) %>% kable()

#point-win by serving status
points_final %>%
  group_by(cu_serving) %>%
  summarize(
    p_win = mean(cu_point_won, na.rm = TRUE),
    n = n()
  ) %>% knitr::kable()
```

CU points wins ~50.36% of all points, regardless of serving.
CU served ~50.19% of the rallies, roughly an equal distribution.

Side-out success ~ 58.35%
CU wins ~ 58.35% of points when receiving the serve(side-out success).

CU wins ~42.04% of points when serving.
CU wins ~58.75% of points when receiving the serve.

*Exploration Plots*

```{r}
#Distribution of substitutions per rally
ggplot(points_final, aes(x = substitution_after_point)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Distribution of Substitutions After Rallies",
       x = "Substitution Occurred?",
       y = "Number of Rallies")

#Substitution effect on CU points
points_final %>%
  group_by(substitution_after_point) %>%
  summarize(
    avg_cu_point = mean(cu_point_won, na.rm = TRUE),
    n = n()
  ) %>% kable()
```

```{r}
#serve impact bar plot
points_final %>%
  group_by(cu_serving) %>%
  summarise(win_prob = mean(cu_point_won, na.rm = TRUE)) %>%
  ggplot(aes(x = cu_serving, y = win_prob, fill = cu_serving)) +
  geom_col() +
  labs(title = "Effect of Serving on Rally Win Probability",
       x = "CU Serving?", y = "Win Probability")
```

```{r}
#rally vs score dynamics 
#win rate by score difference
points_final %>%
  mutate(score_bin = cut(cu_score_diff_end, breaks = seq(-10, 10, 2))) %>%
  group_by(score_bin) %>%
  summarise(win_prob = mean(cu_point_won, na.rm = TRUE)) %>%
  ggplot(aes(x = score_bin, y = win_prob)) +
  geom_col(fill = "steelblue") +
  labs(title = "CU Rally Win Probability by Score Differential",
       x = "Score Differential (CU - Opp)", y = "Probability of Winning Next Rally")
```
Shows how win chances shift as CU leads or trails, key for identifying leverage state.

```{r}
#Momentum/ Run Length Analysis 
# Win probability conditional on previous rally outcome
points_final %>%
  group_by(prev_win) %>%
  summarise(win_prob = mean(cu_point_won, na.rm = TRUE)) %>%
  ggplot(aes(x = as.factor(prev_win), y = win_prob, fill = as.factor(prev_win))) +
  geom_col() +
  labs(title = "Momentum Effect: Win Probability by Previous Rally Outcome",
       x = "Won Previous Rally?", y = "Probability of Winning Next Rally")

# Distribution of rally run lengths
points_final %>%
  ggplot(aes(x = run_length)) +
  geom_histogram(binwidth = 1, fill = "goldenrod", color = "black") +
  labs(title = "Distribution of Rally Run Lengths", x = "Run Length", y = "Frequency")
```
Tests whether winning or losing streaks affect rally outcomes.

```{r}
#seasonal patterns 
points_final %>%
  group_by(season) %>%
  summarise(season_win_rate = mean(cu_point_won, na.rm = TRUE)) %>%
  ggplot(aes(x = as.numeric(season), y = season_win_rate)) +
  geom_line(linewidth = 1.2, color = "darkblue") +
  geom_point(size = 2) +
  labs(title = "CU Rally Win Rate Across Seasons",
       x = "Season", y = "Win Rate")
```


pbp dataset 
variables: match_id, date, season, conference, home_team, visiting_team, set_number, rally_ud, cu_serving, cu_score_pre, opp_score_pre, d_pre, cu_score_end, opp_score_end, cu_score_diff_end, cu_point_won, deciding_set, rally_importance, close_score, rally_in_match, rall_prop_in_match, run_length, prev_win, final_home_set_score, final_away_set_score, won_set, touches_in_rally, timeout_after_point, substitution_after_point, won_match_rally

pbp2 dataset 
-adds y and cu_serve to variables 

##Basic Logistic Regression Model
*Use points_final dataset for modeling*.
```{r}
pbp <- points_final

pbp2 <- pbp %>%
  mutate(
    y  = as.integer(cu_point_won),          #1 if CU won rally, 0 otherwise
    cu_serv = as.integer(cu_serving)
  ) %>%
  filter(y %in% c(0,1), cu_serv %in% c(0,1)) %>%
  drop_na(y, d_pre, cu_serv)
```

```{r}
#logistic regression model(markov transition model)
m_point <- glm(
  y ~ d_pre + I(d_pre^2) + cu_serv,
  data = pbp2, family = binomial()
)
summary(m_point)
coef(m_point)  
#forms transition kernel of the markov chain 
```


#Logstic Regression Dignostic Testing 
A. Logistic Regression (Rally-Level Markov Model) Diagnostics
```{r}
#Residual Analysis
# Pearson residuals
resid_pearson <- residuals(m_point, type = "pearson")
hist(resid_pearson, breaks = 50, main = "Histogram of Pearson Residuals", xlab = "Residual")

plot(fitted(m_point), residuals(m_point, type = "pearson"))
abline(h = 0, col = "red")

# Pearson residuals
res_pearson <- residuals(m_point, type = "pearson")
summary(res_pearson)
mean(res_pearson^2)  # should be ~1 if model fits well
```

```{r}
#1: Independence of Observations
# Check for potential clustering (e.g., by match, player, or set)
table(pbp2$match_id)    # if you have match_id
table(pbp2$set_number)  # if repeated rallies occur within the same set
```

```{r}
#2: Multicollinearity Check
car::vif(m_point)
```

This is good, all VIF values (1.071186, 1.013266, 1.057551) close to 1 means little to no multicollinearity concern.
VIF > 5 → potential multicollinearity concern 

```{r}
# 3: Linearity in Log odds

# You can only test continuous predictors, so exclude factors like cu_serv
pbp2$d_pre_log <- pbp2$d_pre * log(abs(pbp2$d_pre) + 1)
m_bt <- glm(y ~ d_pre + d_pre_log + cu_serv, data = pbp2, family = binomial())
summary(m_bt)

visreg(m_point, "d_pre", scale = "response") #Visual Check: Partial Residual Plot
```

```{r}
#4: Suffiecent sample size 
# Number of events (1's)
n_events <- sum(pbp2$y == 1, na.rm = TRUE)

# Number of predictors (excluding intercept)
n_predictors <- length(coef(m_point)) - 1

EPV <- n_events / n_predictors
EPV
```
EPV ≥ 10 → model is likely stable


#Logstic Regression Implemented Into Markov Chain
```{r}
#Probability function for Model Predictions 
CLAMP_DIFF <- 12L
clamp <- function(x, lo, hi) pmax(lo, pmin(hi, x))

#returns predicted win probability given any score differential + serving status 
p_hat <- (function(beta) {
  b0 <- unname(beta["(Intercept)"])
  b1 <- unname(beta["d_pre"])
  b2 <- unname(beta["I(d_pre^2)"])
  b3 <- unname(beta["cu_serv"])
  function(d_pre, cu_serv){
    d <- clamp(d_pre, -CLAMP_DIFF, CLAMP_DIFF)
    eta <- b0 + b1*d + b2*(d^2) + b3*as.numeric(cu_serv) 
    plogis(eta)
  }
})(coef(m_point))
```

```{r}
#Markov Chain Value Iteration Setup 
#(win by 2, to 25+)
TARGET     <- 25L
MAX_SCORE  <- 50L   # generous cap to cover long deuce stretches
SERVERS    <- 0:1   # 0 = opp serve, 1 = CU serve

# Array V[cu+1, opp+1, srv+1] stores CU set win prob from that state
V <- array(0, dim = c(MAX_SCORE+1, MAX_SCORE+1, 2))

#terminal states 
is_terminal <- function(cu, opp) {
  (cu >= TARGET || opp >= TARGET) && abs(cu - opp) >= 2
}

# Initialize terminal states
for (cu in 0:MAX_SCORE) {
  for (opp in 0:MAX_SCORE) {
    if (is_terminal(cu, opp)) {
      val <- if (cu > opp) 1.0 else 0.0
      V[cu+1, opp+1, 1] <- val
      V[cu+1, opp+1, 2] <- val
    }
  }
}

#value iteration 
step_value <- function(V){
  Vnew <- V
  for (cu in 0:MAX_SCORE) {
    for (opp in 0:MAX_SCORE) {
      for (srv in SERVERS) {
        if (is_terminal(cu, opp)) next
        # CU rally win probability from (cu, opp, srv):
        p <- p_hat(cu - opp, srv)
        # Transitions:
        cu_win_cu   <- min(cu + 1L, MAX_SCORE)
        cu_win_opp  <- opp
        cu_win_srv  <- 1L  # CU serves after CU wins rally
        cu_lose_cu  <- cu
        cu_lose_opp <- min(opp + 1L, MAX_SCORE)
        cu_lose_srv <- 0L  # OPP serves after CU loses rally
        Vnew[cu+1, opp+1, srv+1] <-
          p * V[cu_win_cu+1,  cu_win_opp+1,  cu_win_srv+1] +
          (1-p) * V[cu_lose_cu+1, cu_lose_opp+1, cu_lose_srv+1]
      }
    }
  }
  Vnew
}

# Iterate to convergence
max_iters <- 400L
tol <- 1e-10
for (it in 1:max_iters) {
  Vnew <- step_value(V)
  delta <- max(abs(Vnew - V))
  V <- Vnew
  if (delta < tol) {
    message(sprintf("Converged in %d iterations (delta=%.3g)", it, delta))
    break
  }
}
```

```{r}
#extracting + viewing results 
v_state <- function(cu, opp, cu_serve) {
  V[cu+1, opp+1, cu_serve+1]
}
```

```{r}
#key state table
key_states <- tribble(
  ~state,                         ~cu, ~opp, ~srv,
  "Start (0-0, CU serve)",         0L,  0L,   1L,
  "Start (0-0, OPP serve)",        0L,  0L,   0L,
  "Late: 24-23, CU serve",        24L, 23L,   1L,
  "Late: 24-23, OPP serve",       24L, 23L,   0L,
  "Late: 23-24, CU serve",        23L, 24L,   1L,
  "Late: 23-24, OPP serve",       23L, 24L,   0L
) %>%
  mutate(
    cu_serve = if_else(srv == 1L, "Yes", "No"),
    `CU set win probability` = pmap_dbl(list(cu, opp, srv), ~ v_state(..1, ..2, ..3))
  ) %>%
  select(state, cu_points = cu, opp_points = opp, cu_serve, `CU set win probability`)

knitr::kable(key_states, digits = 4, align = c("l","r","r","c","r"))

key_states

#export to github
table_md <- kable(key_states, format = "markdown")
writeLines(table_md, "key_states_from_logstic_table.md")
```

```{r}
#deuce region grid 
deuce_grid <- expand.grid(
  cu  = 22:25,
  opp = 22:25,
  srv = c(1L, 0L)
) %>%
  as_tibble() %>%
  mutate(
    cu_serve = if_else(srv == 1L, "Yes", "No"),
    `CU set win probability` = pmap_dbl(list(cu, opp, srv), ~ v_state(..1, ..2, ..3))
  ) %>%
  arrange(cu, opp, desc(cu_serve)) %>%
  select(cu_points = cu, opp_points = opp, cu_serve, `CU set win probability`)

knitr::kable(deuce_grid, digits = 4)

deuce_grid

#export to github
table_md <- kable(deuce_grid, format = "markdown")
writeLines(table_md, "deuce_grid_from_logstic_table.md")
```

```{r}
#Function: return CU set win probability for any state
get_set_win_prob <- function(cu_points, opp_points, cu_serving) {
  # cu_points: integer (0–25+)
  # opp_points: integer (0–25+)
  # cu_serving: 1 if CU serving, 0 if opponent serving
  
  # Clamp inputs to grid boundaries
  cu <- pmin(pmax(cu_points, 0L), MAX_SCORE)
  opp <- pmin(pmax(opp_points, 0L), MAX_SCORE)
  srv <- ifelse(cu_serving %in% c(1, TRUE), 1L, 0L)
  
  # Retrieve from the Markov value matrix V
  prob <- V[cu + 1, opp + 1, srv + 1]
  return(prob)
}
```

```{r}
# Example 1: Start of set, CU serving
get_set_win_prob(0, 0, 1)
# Example 2: Start of set, Opp serving
get_set_win_prob(0, 0, 0)
# Example 3: Deuce scenario (24-23, CU serve)
get_set_win_prob(24, 23, 1)
# Example 4: Opponent leads 22-24, opponent serving
get_set_win_prob(22, 24, 0)
get_set_win_prob(15,19,0)
get_set_win_prob(15,15,1)
get_set_win_prob(15,15,0)
```

```{r}
build_grid_safe <- function(range_limit = 30L) {
  stopifnot(exists("V"), exists("get_set_win_prob"))
  expand.grid(
    cu  = 0:range_limit,
    opp = 0:range_limit,
    srv = c(0L, 1L)        # 0 = opp serve, 1 = CU serve
  ) %>%
    as_tibble() %>%
    mutate(
      cu_serve = if_else(srv == 1L, "CU serve", "Opp serve"),
      prob = pmap_dbl(
        list(cu, opp, srv),
        ~ get_set_win_prob(..1, ..2, ..3)  # one lookup per row
      )
    )
}

grid30 <- build_grid_safe(30L)  #1922 by 5 vars.
```

```{r}
build_deuce_band <- function(lo = 22L, hi = 30L) {
  expand.grid(
    cu  = lo:hi,
    opp = lo:hi,
    srv = c(0L, 1L)
  ) %>%
    as_tibble() %>%
    mutate(
      cu_serve = if_else(srv == 1L, "CU serve", "Opp serve"),
      prob = pmap_dbl(list(cu, opp, srv), ~ get_set_win_prob(..1, ..2, ..3))
    )
}
band <- build_deuce_band(22L, 30L)
```

Visualization of Logstic Regression Markov Chain.
```{r}
# 1) Heatmap by serving status
ggplot(grid30, aes(x = opp, y = cu, fill = prob)) +
  geom_tile() +
  facet_wrap(~ cu_serve) +
  scale_fill_viridis_c(name = "CU Set Win\nProbability", limits = c(0,1)) +
  coord_equal() +
  labs(x = "Opponent Points", y = "CU Points",
       title = "Set Win Probability Across Score States By Serving Team") +
  theme_minimal(base_size = 12)

# 2) Deuce band with contours
ggplot(band, aes(x = opp, y = cu)) +
  geom_tile(aes(fill = prob)) +
  geom_contour(aes(z = prob), breaks = seq(0.5, 0.9, by = 0.05),
               color = "white", linewidth = 0.35) +
  facet_wrap(~ cu_serve) +
  scale_fill_viridis_c(name = "CU Set Win\nProbability", limits = c(0,1)) +
  coord_equal() +
  labs(x = "Opponent points", y = "CU Points",
       title = "Deuce band (22–30): Set Win Probability by Serving Team") +
  theme_minimal(base_size = 12)
```

```{r}
# Create a dataframe of all possible score states and serve conditions
make_state_df <- function(max_score = 30L) {
  expand.grid(
    cu_points  = 0:max_score,
    opp_points = 0:max_score,
    cu_serving = c(0L, 1L)   # 0 = Opp serve, 1 = CU serve
  ) %>%
    as_tibble() %>%
    mutate(
      cu_serve_label = if_else(cu_serving == 1L, "CU serve", "Opp serve"),
      win_probability = pmap_dbl(
        list(cu_points, opp_points, cu_serving),
        ~ get_set_win_prob(..1, ..2, ..3)
      )
    )
}

# Generate for 0–30 range
state_df <- make_state_df(30L)
write.csv(state_df, "state_df_from_logistic.csv", row.names = FALSE)

# Preview
dplyr::glimpse(state_df)
```


##Basic GAM Model
*Use points_final dataset for modeling*.
```{r}
#predictors
points_tomod <- points_final %>%
  mutate(
    y = as.integer(cu_point_won),                  # outcome: CU wins rally (0/1)
    cu_serv = as.integer(cu_serving),             # 0/1 serving
  ) %>%
  filter(y %in% c(0,1), cu_serv %in% c(0,1))
```

```{r}
#GAM model 
m_point_gam <- gam(
  y ~ 
    s(d_pre) +                  # smooth effect of score difference
    cu_serv,                     
  data = points_tomod,
  family = binomial(link = "logit")
)
summary(m_point_gam)
```

#Diagonsitc checks for GAM
```{r}
#1: Linearity in  Logit 
# View smooth term summary and edf
summary(m_point_gam)

# Visualize the smooth effect
plot(m_point_gam, residuals = TRUE, pch = 19, cex = 0.3, shade = TRUE)
gam.check(m_point_gam)   # Check model diagnostics including k-index (basis adequacy)
```

As seen in the summary output of the GAM model, the smoothed term is significant and the edf is about 1 meeting the linearity in the link function assumption to hold very well.Along with a k value of 9 confirms the model used enough flexibility as seen with k to fit the data, but is not underfitting or over-smoothing.


```{r}
#2. Additivity 
# Add interaction term to test additivity
m_point_gam_int <- gam(
  y ~ s(d_pre, by = cu_serv) + cu_serv,
  family = binomial(link = "logit"),
  data = points_tomod
)

# Compare additive vs interaction (non-additive) models
AIC(m_point_gam, m_point_gam_int)
anova(m_point_gam, m_point_gam_int, test = "Chisq")
```

Testing for additvity for a continuous by binary. In a new GAM fit a separate smoothing factor of pre-rally score differential for each serving condition (CU serving vs not serving), while also including the main effect of CU serving. Comparing our additive model with the newly created interaction (non-additive) model. The interaction model has a higher AIC (37419.51) than the additive model (37410.47), meaning a worse model fit. The deviance difference (-8.0992) is negative, meaning adding the interaction actually made the model fit slightly worse aswell. Therefore the simpler additive model is preferred and it fits slightly better than the more complex interaction model, satisfying the additivty assumption.


##GAM Implemented in Markov Chain 
```{r}
# --- Probability function p_hat(d_pre, cu_serv) for GAM ---
CLAMP_DIFF <- 12L

clamp <- function(x, lo, hi) pmax(lo, pmin(hi, x))

p_hat <- (function(model_gam){
  # Returns a function that takes d_pre and cu_serv and outputs probability
  function(d_pre, cu_serv){
    # Clamp d_pre to reasonable range
    d <- clamp(d_pre, -CLAMP_DIFF, CLAMP_DIFF)
    # Construct a new data frame to pass to predict()
    newdata <- data.frame(
      d_pre = d,
      #run_length = 1,   # optionally set default rally length if unknown
      cu_serv = as.numeric(cu_serv)
    )
    # If your GAM includes s(d_pre, by = cu_serv) interaction, we need to keep cu_serv in newdata
    pred <- predict(model_gam, newdata = newdata, type = "response")
    as.numeric(pred)
  }
})(m_point_gam)
```

```{r}
# --- Absorbing Markov chain via VALUE ITERATION (win by 2, to 25+) ---
TARGET     <- 25L
MAX_SCORE  <- 50L   # generous cap to cover long deuce stretches
SERVERS    <- 0:1   # 0 = opp serve, 1 = CU serve

# Array V[cu+1, opp+1, srv+1] stores CU set win prob from that state
V <- array(0, dim = c(MAX_SCORE+1, MAX_SCORE+1, 2))

is_terminal <- function(cu, opp) {
  (cu >= TARGET || opp >= TARGET) && abs(cu - opp) >= 2
}

# Initialize terminal states
for (cu in 0:MAX_SCORE) {
  for (opp in 0:MAX_SCORE) {
    if (is_terminal(cu, opp)) {
      val <- if (cu > opp) 1.0 else 0.0
      V[cu+1, opp+1, 1] <- val
      V[cu+1, opp+1, 2] <- val
    }
  }
}

step_value <- function(V){
  Vnew <- V
  for (cu in 0:MAX_SCORE) {
    for (opp in 0:MAX_SCORE) {
      for (srv in SERVERS) {
        if (is_terminal(cu, opp)) next
        # CU rally win probability from (cu, opp, srv):
        p <- p_hat(cu - opp, srv)
        # Transitions:
        cu_win_cu   <- min(cu + 1L, MAX_SCORE)
        cu_win_opp  <- opp
        cu_win_srv  <- 1L  # CU serves after CU wins rally
        cu_lose_cu  <- cu
        cu_lose_opp <- min(opp + 1L, MAX_SCORE)
        cu_lose_srv <- 0L  # OPP serves after CU loses rally
        Vnew[cu+1, opp+1, srv+1] <-
          p * V[cu_win_cu+1,  cu_win_opp+1,  cu_win_srv+1] +
          (1-p) * V[cu_lose_cu+1, cu_lose_opp+1, cu_lose_srv+1]
      }
    }
  }
  Vnew
}
```

```{r}
# Iterate to convergence
max_iters <- 400L
tol <- 1e-10
for (it in 1:max_iters) {
  Vnew <- step_value(V)
  delta <- max(abs(Vnew - V))
  V <- Vnew
  if (delta < tol) {
    message(sprintf("Converged in %d iterations (delta=%.3g)", it, delta))
    break
  }
}
```

```{r}
# --- Helper to read value from array ---
v_state <- function(cu, opp, cu_serve) {
  V[cu+1, opp+1, cu_serve+1]
}
```

```{r}
# --- Key states table ---
key_states1 <- tribble(
  ~state,                         ~cu, ~opp, ~srv,
  "Start (0-0, CU serve)",         0L,  0L,   1L,
  "Start (0-0, OPP serve)",        0L,  0L,   0L,
  "Late: 24-23, CU serve",        24L, 23L,   1L,
  "Late: 24-23, OPP serve",       24L, 23L,   0L,
  "Late: 23-24, CU serve",        23L, 24L,   1L,
  "Late: 23-24, OPP serve",       23L, 24L,   0L
) %>%
  mutate(
    cu_serve = if_else(srv == 1L, "Yes", "No"),
    `CU set win probability` = pmap_dbl(list(cu, opp, srv), ~ v_state(..1, ..2, ..3))
  ) %>%
  select(state, cu_points = cu, opp_points = opp, cu_serve, `CU set win probability`)

knitr::kable(key_states1, digits = 4, align = c("l","r","r","c","r"))

key_states1

table_md1 <- kable(key_states1, format = "markdown")
writeLines(table_md1, "key_states_from_GAM_table.md")
```

```{r}
# --- Deuce-region grid (22..25) for both serve statuses ---
deuce_grid1 <- expand.grid(
  cu  = 22:25,
  opp = 22:25,
  srv = c(1L, 0L)
) %>%
  as_tibble() %>%
  mutate(
    cu_serve = if_else(srv == 1L, "Yes", "No"),
    `CU set win probability` = pmap_dbl(list(cu, opp, srv), ~ v_state(..1, ..2, ..3))
  ) %>%
  arrange(cu, opp, desc(cu_serve)) %>%
  select(cu_points = cu, opp_points = opp, cu_serve, `CU set win probability`)

knitr::kable(deuce_grid1, digits = 4)

deuce_grid1

table_md1 <- kable(deuce_grid1, format = "markdown")
writeLines(table_md1, "deuce_grid_from_GAM_table.md")
```

```{r}
# --- Function: return CU set win probability for any state ---
get_set_win_prob <- function(cu_points, opp_points, cu_serving) {
  # cu_points: integer (0–25+)
  # opp_points: integer (0–25+)
  # cu_serving: 1 if CU serving, 0 if opponent serving
  
  # Clamp inputs to grid boundaries
  cu <- pmin(pmax(cu_points, 0L), MAX_SCORE)
  opp <- pmin(pmax(opp_points, 0L), MAX_SCORE)
  srv <- ifelse(cu_serving %in% c(1, TRUE), 1L, 0L)
  
  # Retrieve from the Markov value matrix V
  prob <- V[cu + 1, opp + 1, srv + 1]
  return(prob)
}
```

```{r}
# Example 1: Start of set, CU serving
get_set_win_prob(0, 0, 1)
# Example 2: Start of set, Opp serving
get_set_win_prob(0, 0, 0)
# Example 3: Deuce scenario (24-23, CU serve)
get_set_win_prob(24, 23, 1)
# Example 4: Opponent leads 22-24, opponent serving
get_set_win_prob(22, 24, 0)
get_set_win_prob(15,19,0)
get_set_win_prob(15,15,1)
get_set_win_prob(15,15,0)
```

```{r}
build_grid_safe <- function(range_limit = 30L) {
  stopifnot(exists("V"), exists("get_set_win_prob"))
  expand.grid(
    cu  = 0:range_limit,
    opp = 0:range_limit,
    srv = c(0L, 1L)        # 0 = opp serve, 1 = CU serve
  ) %>%
    as_tibble() %>%
    mutate(
      cu_serve = if_else(srv == 1L, "CU serve", "Opp serve"),
      prob = pmap_dbl(
        list(cu, opp, srv),
        ~ get_set_win_prob(..1, ..2, ..3)  # one lookup per row
      )
    )
}

grid30_GAM <- build_grid_safe(30L)
```

```{r}
build_deuce_band <- function(lo = 22L, hi = 30L) {
  expand.grid(
    cu  = lo:hi,
    opp = lo:hi,
    srv = c(0L, 1L)
  ) %>%
    as_tibble() %>%
    mutate(
      cu_serve = if_else(srv == 1L, "CU serve", "Opp serve"),
      prob = pmap_dbl(list(cu, opp, srv), ~ get_set_win_prob(..1, ..2, ..3))
    )
}
band <- build_deuce_band(22L, 30L)
```

```{r}
# 1) Heatmap by serving status
ggplot(grid30_GAM, aes(x = opp, y = cu, fill = prob)) +
  geom_tile() +
  facet_wrap(~ cu_serve) +
  scale_fill_viridis_c(name = "CU Set Win\nProbability", limits = c(0,1)) +
  coord_equal() +
  labs(x = "Opponent Points", y = "CU Points",
       title = "Set Win Probability Across Score States by Serving Team") +
  theme_minimal(base_size = 12)

# 2) Deuce band with contours
ggplot(band, aes(x = opp, y = cu)) +
  geom_tile(aes(fill = prob)) +
  geom_contour(aes(z = prob), breaks = seq(0.5, 0.9, by = 0.05),
               color = "white", linewidth = 0.35) +
  facet_wrap(~ cu_serve) +
  scale_fill_viridis_c(name = "CU set Win\nProbability", limits = c(0,1)) +
  coord_equal() +
  labs(x = "Opponent Points", y = "CU Points",
       title = "Deuce Band (22–30): Set Win Probability by Serving Team") +
  theme_minimal(base_size = 12)
```

```{r}
# Create a dataframe of all possible score states and serve conditions
make_state_df <- function(max_score = 30L) {
  expand.grid(
    cu_points  = 0:max_score,
    opp_points = 0:max_score,
    cu_serving = c(0L, 1L)   # 0 = Opp serve, 1 = CU serve
  ) %>%
    as_tibble() %>%
    mutate(
      cu_serve_label = if_else(cu_serving == 1L, "CU serve", "Opp serve"),
      win_probability = pmap_dbl(
        list(cu_points, opp_points, cu_serving),
        ~ get_set_win_prob(..1, ..2, ..3)
      )
    )
}

# Generate for 0–30 range
state_df_GAM <- make_state_df(30L)

# Preview
dplyr::glimpse(state_df_GAM)
```


##Model Validation 
*Validate GAM first*
```{r}
points_tomod %>%
  mutate(pred_prob = predict(m_point_gam, type = "response")) %>%
  mutate(prob_bin = cut(pred_prob, breaks = seq(0, 1, 0.1))) %>%
  group_by(prob_bin) %>%
  summarise(obs_rate = mean(y), mean_pred = mean(pred_prob)) %>%
  ggplot(aes(x = mean_pred, y = obs_rate)) +
  geom_point() + geom_abline(slope = 1, intercept = 0, linetype="dashed") +
  labs(x="Predicted Probability", y="Observed Proportion", title="Calibration plot")
```

```{r}
library(pROC)
roc_obj <- roc(points_tomod$y, predict(m_point_gam, type="response"))
auc(roc_obj)
plot(roc_obj) #AUC: 0.599 
```


##5-Fold CV Model Validation for GAM Contd.(CHASE)
```{r}
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(ggplot2)
  library(mgcv); library(pROC); library(readr); library(tibble)
})

df <- readr::read_csv("points_final.csv", show_col_types = FALSE)

gam_df <- df %>%
  transmute(
    match_id,
    set_number,
    y = as.integer(cu_point_won),
    d_pre,
    cu_serv = as.integer(cu_serving)
  ) %>% drop_na()

m_gam <- mgcv::gam(y ~ s(d_pre) + cu_serv, data = gam_df, family = binomial())
print(summary(m_gam))

# 5-fold CV by match
set.seed(22)
ids <- unique(gam_df$match_id)
folds <- split(ids, cut(seq_along(ids), 5, labels = FALSE))
res <- lapply(1:5, function(k){
  tr <- gam_df %>% filter(!match_id %in% folds[[k]])
  te <- gam_df %>% filter( match_id %in% folds[[k]])
  m  <- mgcv::gam(y ~ s(d_pre) + cu_serv, data = tr, family = binomial())
  p  <- predict(m, newdata = te, type = "response")
  eps <- 1e-9
  data.frame(
    fold=k,
    auc = as.numeric(pROC::auc(te$y, p)),
    logloss = -mean(te$y*log(p+eps) + (1-te$y)*log(1-p+eps)),
    brier = mean((p-te$y)^2)
  )
})
cv_tbl <- dplyr::bind_rows(res)
print(cv_tbl)
print(colMeans(cv_tbl[,c("auc","logloss","brier")]))
```

```{r}
p_hat <- function(d, s) as.numeric(predict(m_gam, data.frame(d_pre=d, cu_serv=as.integer(s)), type="response"))
TARGET <- 25; MAX <- 50
V <- array(0, dim=c(MAX+1, MAX+1, 2))
is_term <- function(cu,op) (cu>=TARGET || op>=TARGET) && abs(cu-op)>=2
for(cu in 0:MAX) for(op in 0:MAX) if(is_term(cu,op)){ val <- as.integer(cu>op); V[cu+1,op+1,] <- val }

value_step <- function(V){
  Vn <- V
  for(cu in 0:MAX) for(op in 0:MAX) for(s in 0:1){
    if(is_term(cu,op)) next
    p <- p_hat(cu-op, s)
    win  <- V[min(cu+1,MAX)+1, op+1, 2]   # CU serves after win
    lose <- V[cu+1, min(op+1,MAX)+1, 1]   # Opp serves after loss
    Vn[cu+1,op+1,s+1] <- p*win + (1-p)*lose
  }
  Vn
}
for(it in 1:300){
  Vn <- value_step(V)
  if(max(abs(Vn - V)) < 1e-10) { V <- Vn; break }
  V <- Vn
}
v_state <- function(cu,op,s) V[cu+1,op+1,s+1]

print(v_state(0,0,1))
print(v_state(24,23,1))
print(v_state(23,24,0))
```

```{r}
p_hat_rally <- predict(m_gam, newdata = gam_df, type = "response")
cuts <- cut(p_hat_rally, breaks = quantile(p_hat_rally, probs = seq(0,1,0.1)),
            include.lowest = TRUE, labels = FALSE)
calib <- gam_df %>%
  mutate(bin = cuts, phat = p_hat_rally) %>%
  group_by(bin) %>%
  summarise(phat = mean(phat), ybar = mean(y), n = dplyr::n(), .groups="drop")

readr::write_csv(cv_tbl, "cv_gam_rally_metrics.csv")
readr::write_csv(calib, "calibration_rally_deciles.csv")

ggplot(calib, aes(phat, ybar, size=n)) +
  geom_point(alpha=.85,color="lightblue") +
  geom_abline(slope=1, intercept=0, linetype=2) +
  labs(x="Predicted Rally-Win Probability", y="Observed Rally-Win Rate",
       title="Rally-Level Calibration (GAM)") +
  theme_minimal()
ggsave("calibration_rally_deciles.png", width=6.5, height=4.5, dpi=300)

# Key states table
key_states <- tibble::tribble(
  ~state, ~cu, ~opp, ~srv,
  "Start (0-0, CU serve)", 0L, 0L, 1L,
  "Start (0-0, OPP serve)",0L, 0L, 0L,
  "24-23, CU serve",       24L,23L, 1L,
  "24-23, OPP serve",      24L,23L, 0L,
  "23-24, CU serve",       23L,24L, 1L,
  "23-24, OPP serve",      23L,24L, 0L
) |> dplyr::mutate(prob = purrr::pmap_dbl(list(cu,opp,srv), ~ v_state(..1,..2,..3)))
readr::write_csv(key_states, "key_states_markov_from_GAM.csv")
print(key_states)
```



##ACTUAL MARKOV VALIDATION
*Validate the Markov chain component (set-level / match-level probabilities)*
```{r}
pred_set_win <- mapply(get_set_win_prob,
                       cu_points = pbp2$cu_score_end,
                       opp_points = pbp2$opp_score_end,
                       cu_serving = pbp2$cu_serving)

# Actual observed outcome: 1 if CU won, 0 otherwise
actual_set_win <- pbp2$won_set01

sets_df <- pbp2 %>%
  group_by(match_id, set_number) %>%
  # take the final rally row for each set (should contain final scores and won_set)
  slice_tail(n = 1) %>%
  ungroup() %>%
  mutate(
    pred_set_win = mapply(get_set_win_prob,
                          cu_points = cu_score_end,
                          opp_points = opp_score_end,
                          cu_serving = cu_serving)
  )
# 4) Compute Brier & Log-loss using only complete cases
sets_complete <- sets_df %>% filter(!is.na(pred_set_win) & !is.na(won_set))

actual <- as.numeric(sets_complete$won_set)   # 1/0
pred   <- as.numeric(sets_complete$pred_set_win)

# Safety clamp for log loss
eps <- 1e-15
pred_clamped <- pmin(pmax(pred, eps), 1 - eps)

# Metrics
brier_model <- mean((pred - actual)^2)
log_loss    <- -mean(actual * log(pred_clamped) + (1 - actual) * log(1 - pred_clamped))

# Null baselines (per-set)
cu_overall_win_rate <- mean(actual)      # empirical set-win rate
brier_null_constant <- mean((cu_overall_win_rate - actual)^2)
brier_null_random   <- mean((0.5 - actual)^2)

# Print results
tibble(
  Model = c("Markov+GAM (per-set)", "Null: overall win rate", "Null: random 0.5"),
  Brier = c(brier_model, brier_null_constant, brier_null_random),
  LogLoss = c(log_loss, NA_real_, NA_real_)
) %>% print()
```



```{r}
# --- 3. Simulation-based validation: simulate full sets ---
is_terminal <- function(cu, opp, TARGET = 25L){
(cu >= TARGET || opp >= TARGET) && abs(cu - opp) >= 2
}

simulate_set <- function(cu_serv_start = 1){
cu <- 0L
opp <- 0L
srv <- cu_serv_start
while(!is_terminal(cu, opp)){
p <- get_set_win_prob(cu, opp, srv)
rally_win <- rbinom(1, 1, p)
if(rally_win == 1){
cu <- cu + 1L
srv <- 1L
} else {
opp <- opp + 1L
srv <- 0L
}
}
cu > opp  # TRUE if CU wins the set
}

# Simulate many sets
set.seed(22)
n_sim <- 10000
sim_results <- replicate(n_sim, simulate_set(cu_serv_start = sample(0:1,1)))

pbp2 <- pbp2 %>%
  mutate(won_set=as.numeric(won_set))
# Compare simulated overall set win probability to historical fraction
sim_mean <- mean(sim_results)
hist_mean <- mean(pbp2$won_set)

#compare distribution of simulated vs actual set outcomes
table(sim_results)
table(pbp2$won_set)
```
Simulation 
10,000obs:45.16% of the sets were lost // 54.84% of the sets were won 
REAL
27403obs: 46.40% of the sets were lost // 53.59% of the sets were won 

Also by simulating 10,000 sets of data, it is seen that the simulated average (54.84%) of the sets won is close to the historical average (53.59%) of sets won, thus indicating that the markov chain with incorporated GAM has probabilities is producing realistic set outcomes. The model is well-calibrated at the set level.










## RESEARCH QUESTIONS
#Q1: Are there high-leverage scores?
```{r}
points2 <- points_final %>%
  rowwise() %>%  # process row by row
  mutate(
    win_prob_before = get_set_win_prob(cu_score_pre, opp_score_pre, as.integer(cu_serving)),
    win_prob_after  = get_set_win_prob(cu_score_end, opp_score_end, as.integer(cu_serving)),
    leverage = abs(win_prob_after - win_prob_before)
  ) %>%
  ungroup()
#gives leverage score/prob for all 
#High leverage → the rally had a big effect on the set outcome.
```
In volleyball, a "high leverage score" refers to a game situation where the outcome of the current point has a disproportionately large impact on the overall probability of a team winning the match.

Bright/high values = rallies that shifted set win probability a lot.
Dark/low values = rallies with minimal impact on the eventual set win.

“rally importance” metric derived from your Markov chain.
```{r}
ggplot(points2, aes(x = cu_score_end, y = opp_score_end, fill = leverage)) +
  geom_tile() +
  scale_fill_viridis_c(option = "plasma") +
  labs(title = "Rally Leverage: Change in CU Set Win Probability per Rally",
       x = "Opponent Score", y = "CU Score", fill = "Δ Win Probability") +
  coord_equal()
```

#Q2: Are there ways of grouping scores together into discrete categories by their win probabilities?
```{r}
#SAME GRAPHIC AS ABOVE WITHOUT NAs
grid30_GAM %>%
  filter(!is.na(prob)) %>%   # remove NA values
  mutate(
    prob = pmin(pmax(prob, 0), 1),  # clamp probabilities between 0 and 1
    win_group = cut(
      prob, 
      breaks = c(0, 0.25, 0.5, 0.75, 1),
      labels = c("Low (0–25%)", "Medium (25–50%)", "High (50–75%)", "Very High (75–100%)"),
      include.lowest = TRUE
    )
  ) %>%
  ggplot(aes(x = opp, y = cu, fill = win_group)) +
  geom_tile() +
  #facet_wrap(~ cu_serve, labeller = labeller(cu_serve = c("0" = "Opponent Serve", "1" = "CU Serve"))) +
  scale_fill_manual(
    values = c("#F8766D", "#7CAE00", "#00BFC4", "#C77CFF"),
    name = "CU Win Probability"
  ) +
  labs(
    title = "CU Set Win Probability by Score State",
    subtitle = "Heatmap of Win Likelihoods Grouped Into Four Probability Tiers",
    x = "Opponent Score",
    y = "CU Score"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(color = "gray30")
  )
```

Description:
This heatmap visualizes the CU women’s volleyball team’s probability of winning a set based on the current score.
Each tile represents a possible score state (CU score, Opponent score), colored by the estimated win probability group: Low (0–25%), Medium (25–50%), High (50–75%), and Very High (75–100%).
The clear diagonal pattern shows how CU’s chances increase as their score surpasses the opponent’s, with noticeably higher probabilities when CU is serving at key score margins.

```{r}
grid30_GAM %>%
  filter(!is.na(prob)) %>%
  mutate(
    prob_group = ntile(prob, 4),  # splits into 4 equal-frequency groups
    win_group = factor(prob_group, labels = c("Lowest", "Low-Medium", "High-Medium", "Highest"))
  ) %>%
  ggplot(aes(x = opp, y = cu, fill = win_group)) +
  geom_tile() +
  #facet_wrap(~ cu_serve, labeller = labeller(cu_serve = c("0" = "Opponent Serve", "1" = "CU Serve"))) +
  scale_fill_manual(
    values = c("#F8766D", "#7CAE00", "#00BFC4", "#C77CFF"),
    name = "CU Win Probability"
  ) +
  labs(
    title = "CU Set Win Probability by Score State",
    subtitle = "Heatmap of Win Likelihoods Grouped Into Four Probability Tiers",
    x = "Opponent Score",
    y = "CU Score"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold"),
    plot.subtitle = element_text(color = "gray30")
  )
```

Quantile-based grouping: split the probabilities based on their distribution in the data. This ensures roughly equal numbers of tiles in each group.

```{r}
#ADDS the discrete grouping to the dataset
grid30_GAM <- grid30_GAM %>%
  filter(!is.na(prob)) %>%        # remove NAs
  mutate(
    prob_group = ntile(prob, 4),  # split into 4 equal-frequency groups
    win_group = factor(
      prob_group, 
      labels = c("Lowest", "Low-Medium", "High-Medium", "Highest")
    )
  )
```


#Q3: How do win probabilities differ between non-deciding sets and deciding sets?
1st deciding vs non-deciding relation to actual wins from data.
```{r}
# distribution of CU points at set end, by deciding vs non-deciding sets
points_final %>%
  group_by(match_id, set_number) %>%
  slice_tail(n = 1) %>%  # last rally of each set
  ungroup() %>%
  ggplot(aes(x = cu_score_end)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black", alpha = 0.7) +
  facet_wrap(~ deciding_set, 
             labeller = labeller(deciding_set = c(`FALSE` = "Non-Deciding Set", `TRUE` = "Deciding Set"))) +
  labs(
    title = "Distribution of CU Points at Set End",
    x = "CU Points at Set End",
    y = "Count of Sets"
  ) +
  theme_minimal()
```
Non-deciding sets have a greater number of sets with a) greater distribution of points at the sets end b) greater count of sets at a higher (more likely a win) # of points.

```{r}
#before 
t.test(cu_score_end ~ deciding_set, data = points_final)

# Equalize sample sizes by random sampling
points_balanced <- points_final %>%
  group_by(deciding_set) %>%
  sample_n(size = min(table(points_final$deciding_set))) %>%
  ungroup()

# Now run the t-test on balanced data
t.test(cu_score_end ~ deciding_set, data = points_balanced)
```

H₀: mean(CU points | non-deciding) = mean(CU points | deciding)
H₁: they differ.

Even after balancing for the fact that there are usually more non-deciding sets, CU tends to score significantly fewer points in deciding sets compared to non-deciding ones.

```{r}
# Compute group means first
means_df <- points_balanced %>%
  group_by(deciding_set) %>%
  summarize(mean_points = mean(cu_score_end, na.rm = TRUE))

# Plot density + mean lines
ggplot(points_balanced, aes(x = cu_score_end, fill = deciding_set)) +
  geom_density(alpha = 0.5, adjust = 1.2) +
  geom_vline(data = means_df, aes(xintercept = mean_points, color = deciding_set),
             linetype = "dashed", size = 1) +
  scale_fill_manual(values = c("steelblue", "tomato"),
                    labels = c("Non-Deciding Set", "Deciding Set")) +
  scale_color_manual(values = c("steelblue4", "tomato4"), guide = "none") +
  labs(
    title = "Distribution of CU Points at Set End",
    #subtitle = "Dashed lines Indicate mean points per set type",
    x = "CU Points at Set End",
    y = "Density",
    fill = "Set Type"
  ) +
  theme_minimal(base_size = 14)
```


Now using modeling and our data with logistic regression.
```{r}
#might change 
m_deciding <- glm(y ~ d_pre + I(d_pre^2) + cu_serv,
                  data = pbp2, family = binomial(), subset = deciding_set)
m_nondeciding <- glm(y ~ d_pre + I(d_pre^2) + cu_serv,
                     data = pbp2, family = binomial(), subset = !deciding_set)

broom::tidy(m_deciding)
broom::tidy(m_nondeciding)
```

##BIG QUESTION: How do win probabilities change as we go through different scores and through different sets? (+ overall match)

First need diagnostic tests to know our model meets assumptions.
Then model validation/testing of Markov chain model.
Then final plotting + graphics + interpretation of results.
```{r}
#HEATMAP: win probabilities OF EMPIRICAL DATA
points_final %>%
  count(cu_score_end, opp_score_end, wt = cu_point_won, name = "wins") %>%
  left_join(count(points_final, cu_score_end, opp_score_end, name = "total"),
            by = c("cu_score_end", "opp_score_end")) %>%
  mutate(win_prob = wins / total) %>%
  ggplot(aes(x = opp_score_end, y = cu_score_end, fill = win_prob)) +
  geom_tile() +
  scale_fill_viridis_c(option = "plasma") +
  labs(title = "Heatmap of CU Rally Win Probability by Score State",
       x = "Opponent Score", y = "CU Score", fill = "Win Probabilities")
```

OTHER TWO FOR LOGISTIC + GAM are with there respective code sections.
